package main

import (
	"fmt"
	"sync"
	"sync/atomic"
	"time"

	"github.com/bingquanzhao/go-doris-sdk"
)

func main() {
	fmt.Printf("ğŸ”¥ ==================== SDKæ€§èƒ½æé™æµ‹è¯• (å¤§æ‰¹æ¬¡) ====================\n")
	fmt.Printf("ğŸ¯ ç›®æ ‡: ä½¿ç”¨æ›´å¤§æ‰¹æ¬¡æµ‹é‡çœŸå®çš„æ•°æ®å†™å…¥æé™\n\n")

	// Dorisé…ç½®
	config := &doris.Config{
		Endpoints:   []string{"http://10.16.10.6:8630"},
		User:        "root",
		Password:    "123456",
		Database:    "test",
		Table:       "orders",
		Format:      doris.DefaultCSVFormat(),
		Retry:       &doris.Retry{MaxRetryTimes: 2, BaseIntervalMs: 200, MaxTotalTimeMs: 10000},
		GroupCommit: doris.ASYNC,
		Options: map[string]string{
			"timeout": "60", // å¢åŠ è¶…æ—¶æ—¶é—´
		},
	}

	client, err := doris.NewLoadClient(config)
	if err != nil {
		fmt.Printf("âŒ åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: %v\n", err)
		return
	}

	// æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„å½±å“
	fmt.Printf("ğŸ”¬ ==================== æ‰¹æ¬¡å¤§å°å½±å“æµ‹è¯• ====================\n")
	batchSizes := []int{10000, 20000, 50000, 100000}
	concurrency := 4                // å›ºå®š4å¹¶å‘æµ‹è¯•æ‰¹æ¬¡å¤§å°å½±å“
	testDuration := 3 * time.Minute // å¢åŠ åˆ°3åˆ†é’Ÿï¼Œäº§ç”Ÿæ›´å¤šæ•°æ®

	for _, batchSize := range batchSizes {
		fmt.Printf("ğŸ§ª æµ‹è¯•æ‰¹æ¬¡å¤§å°: %d æ¡è®°å½• (4å¹¶å‘, 3åˆ†é’Ÿ)\n", batchSize)
		result := runBatchSizeTest(client, concurrency, batchSize, testDuration)
		printBatchResult(result, batchSize)
		fmt.Printf("   ğŸ“Š é¢„è®¡æ€»æ•°æ®: %.1f GB (æœ¬è½®)\n", float64(result.TotalBytes)/1024/1024/1024)
		time.Sleep(5 * time.Second)
	}

	// ä½¿ç”¨æœ€ä¼˜æ‰¹æ¬¡å¤§å°è¿›è¡Œå¹¶å‘æµ‹è¯•
	optimalBatchSize := 50000 // ä½¿ç”¨5ä¸‡æ¡ï¼Œäº§ç”Ÿæ›´å¤§æ•°æ®é‡
	fmt.Printf("\nğŸš€ ==================== å¹¶å‘çº¿æ€§æ‰©å±•æ€§æµ‹è¯• ====================\n")
	fmt.Printf("ğŸ“¦ ä½¿ç”¨æ‰¹æ¬¡å¤§å°: %d æ¡è®°å½•\n", optimalBatchSize)
	fmt.Printf("ğŸ¯ é‡ç‚¹æŒ‡æ ‡: MB/s ååé‡å’Œå¹¶å‘çº¿æ€§æ‰©å±•æ€§\n")

	concurrencyLevels := []int{1, 2, 4, 8, 16, 32}
	testDuration = 5 * time.Minute // æ¯ä¸ªå¹¶å‘çº§åˆ«æµ‹è¯•5åˆ†é’Ÿï¼Œäº§ç”Ÿå¤§é‡æ•°æ®

	results := make(map[int]map[string]interface{})

	for _, concurrency := range concurrencyLevels {
		fmt.Printf("ğŸš€ æµ‹è¯•å¹¶å‘åº¦: %d (5åˆ†é’Ÿæµ‹è¯•)\n", concurrency)
		result := runConcurrencyTest(client, concurrency, optimalBatchSize, testDuration)
		printConcurrencyResult(result, concurrency)

		// æ˜¾ç¤ºç´¯è®¡æ•°æ®é‡
		totalGB := float64(result.TotalBytes) / 1024 / 1024 / 1024
		fmt.Printf("   ğŸ“Š æœ¬è½®æ€»æ•°æ®: %.2f GB | ç´¯è®¡è¿è¡Œ: %.1f åˆ†é’Ÿ\n", totalGB, testDuration.Minutes())

		results[concurrency] = map[string]interface{}{
			"records_per_sec": result.RecordsPerSec,
			"mb_per_sec":      result.MBPerSec,
			"total_records":   result.TotalRecords,
			"total_bytes":     result.TotalBytes,
			"error_rate":      result.ErrorRate,
			"avg_latency":     result.AvgLatency,
		}

		// å¦‚æœé”™è¯¯ç‡è¿‡é«˜ï¼Œåœæ­¢æµ‹è¯•
		if result.ErrorRate > 20 {
			fmt.Printf("âš ï¸  é”™è¯¯ç‡è¿‡é«˜ (%.1f%%)ï¼Œåœæ­¢åç»­æµ‹è¯•\n", result.ErrorRate)
			break
		}

		time.Sleep(5 * time.Second)
	}

	// æœ€ç»ˆåˆ†æ
	analyzeResults(results, concurrencyLevels)
}

type TestResult struct {
	Concurrency     int
	BatchSize       int
	Duration        time.Duration
	TotalRecords    int64
	TotalBytes      int64
	TotalRequests   int64
	SuccessRequests int64
	FailedRequests  int64
	RecordsPerSec   float64
	MBPerSec        float64
	RequestsPerSec  float64
	AvgLatency      time.Duration
	ErrorRate       float64
}

func runBatchSizeTest(client *doris.DorisLoadClient, concurrency, batchSize int, duration time.Duration) TestResult {
	return runConcurrencyTest(client, concurrency, batchSize, duration)
}

func runConcurrencyTest(client *doris.DorisLoadClient, concurrency, batchSize int, duration time.Duration) TestResult {
	var totalRecords, totalBytes, totalRequests, successCount, failureCount int64
	var totalLatency int64

	startTime := time.Now()
	var wg sync.WaitGroup

	// å¯åŠ¨æ‰€æœ‰worker
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			endTime := time.Now().Add(duration)
			for time.Now().Before(endTime) {
				// ç”Ÿæˆæµ‹è¯•æ•°æ®
				data := generateTestData(workerID, batchSize)
				dataSize := int64(len(data))

				// æ‰§è¡ŒåŠ è½½
				reqStart := time.Now()
				response, err := client.Load(doris.StringReader(data))
				latency := time.Since(reqStart)

				// æ›´æ–°ç»Ÿè®¡
				atomic.AddInt64(&totalRequests, 1)
				atomic.AddInt64(&totalBytes, dataSize)
				atomic.AddInt64(&totalLatency, int64(latency))

				if err != nil || response == nil || response.Status != doris.SUCCESS {
					atomic.AddInt64(&failureCount, 1)
					if err != nil {
						fmt.Printf("   âŒ Worker %d é”™è¯¯: %v\n", workerID, err)
					}
				} else {
					atomic.AddInt64(&successCount, 1)
					atomic.AddInt64(&totalRecords, int64(batchSize))
				}
			}
		}(i)
	}

	wg.Wait()
	actualDuration := time.Since(startTime)

	// è®¡ç®—ç»“æœ
	result := TestResult{
		Concurrency:     concurrency,
		BatchSize:       batchSize,
		Duration:        actualDuration,
		TotalRecords:    totalRecords,
		TotalBytes:      totalBytes,
		TotalRequests:   totalRequests,
		SuccessRequests: successCount,
		FailedRequests:  failureCount,
	}

	seconds := actualDuration.Seconds()
	if seconds > 0 {
		result.RecordsPerSec = float64(totalRecords) / seconds
		result.MBPerSec = float64(totalBytes) / 1024 / 1024 / seconds
		result.RequestsPerSec = float64(totalRequests) / seconds
	}

	if totalRequests > 0 {
		result.AvgLatency = time.Duration(totalLatency / totalRequests)
		result.ErrorRate = float64(failureCount) / float64(totalRequests) * 100
	}

	return result
}

func printBatchResult(result TestResult, batchSize int) {
	fmt.Printf("   ğŸ“Š æ‰¹æ¬¡å¤§å° %d æ¡:\n", batchSize)
	fmt.Printf("      ğŸ“ˆ ååé‡: %.0f records/sec | %.2f MB/sec | %.1f requests/sec\n",
		result.RecordsPerSec, result.MBPerSec, result.RequestsPerSec)
	fmt.Printf("      â±ï¸  å¹³å‡å»¶è¿Ÿ: %v | è¯·æ±‚æ•ˆç‡: %.0f records/request\n",
		result.AvgLatency, float64(result.TotalRecords)/float64(result.TotalRequests))
	fmt.Printf("      âœ… æˆåŠŸç‡: %.1f%% | æ€»æ•°æ®: %d records\n",
		100-result.ErrorRate, result.TotalRecords)
	fmt.Printf("\n")
}

func printConcurrencyResult(result TestResult, concurrency int) {
	fmt.Printf("   ğŸ“Š å¹¶å‘åº¦ %d:\n", concurrency)
	fmt.Printf("      ğŸ“ˆ ååé‡: %.0f records/sec | %.2f MB/sec\n",
		result.RecordsPerSec, result.MBPerSec)
	fmt.Printf("      â±ï¸  å»¶è¿Ÿ: %v | æˆåŠŸç‡: %.1f%%\n",
		result.AvgLatency, 100-result.ErrorRate)
	fmt.Printf("      ğŸ“¦ æ€»æ•°æ®: %d records | %.1f MB\n",
		result.TotalRecords, float64(result.TotalBytes)/1024/1024)
	fmt.Printf("\n")
}

func analyzeResults(results map[int]map[string]interface{}, concurrencyLevels []int) {
	fmt.Printf("ğŸ¯ ==================== æ€§èƒ½åˆ†ææŠ¥å‘Š ====================\n")
	fmt.Printf("å¹¶å‘æ•° | Records/sec | MB/sec | é”™è¯¯ç‡(%%) | å¹³å‡å»¶è¿Ÿ | æ€»è®°å½•æ•°\n")
	fmt.Printf("-------|-------------|--------|----------|----------|----------\n")

	var maxThroughput float64
	var optimalConcurrency int
	var singleConcThroughput float64

	for _, concurrency := range concurrencyLevels {
		result, exists := results[concurrency]
		if !exists {
			continue
		}

		recordsPerSec := result["records_per_sec"].(float64)
		mbPerSec := result["mb_per_sec"].(float64)
		errorRate := result["error_rate"].(float64)
		avgLatency := result["avg_latency"].(time.Duration)
		totalRecords := result["total_records"].(int64)

		fmt.Printf("%-6d | %-11.0f | %-6.2f | %-8.1f | %-8v | %d\n",
			concurrency, recordsPerSec, mbPerSec, errorRate, avgLatency, totalRecords)

		if concurrency == 1 {
			singleConcThroughput = recordsPerSec
		}

		if recordsPerSec > maxThroughput {
			maxThroughput = recordsPerSec
			optimalConcurrency = concurrency
		}
	}

	// è®¡ç®—æ€»æ•°æ®é‡
	var totalDataGB float64
	for _, result := range results {
		if totalBytes, ok := result["total_bytes"].(int64); ok {
			totalDataGB += float64(totalBytes) / 1024 / 1024 / 1024
		}
	}

	// æ€§èƒ½æ€»ç»“
	fmt.Printf("\nğŸ† ==================== æ€§èƒ½æé™æ€»ç»“ ====================\n")
	fmt.Printf("ğŸ—„ï¸ æµ‹è¯•æ€»æ•°æ®é‡: %.2f GB\n", totalDataGB)
	if singleConcThroughput > 0 {
		fmt.Printf("ğŸ“Š å•å¹¶å‘æ€§èƒ½åŸºå‡†: %.0f records/sec | %.2f MB/sec\n",
			singleConcThroughput, results[1]["mb_per_sec"].(float64))
		fmt.Printf("ğŸš€ æœ€å¤§ååé‡: %.0f records/sec (%d å¹¶å‘)\n", maxThroughput, optimalConcurrency)
		scalingEfficiency := (maxThroughput / singleConcThroughput) / float64(optimalConcurrency) * 100
		fmt.Printf("ğŸ“ˆ æ€§èƒ½æå‡å€æ•°: %.1fx | æ‰©å±•æ•ˆç‡: %.1f%%\n", maxThroughput/singleConcThroughput, scalingEfficiency)
	}

	// å…³é”®å‘ç°
	fmt.Printf("\nğŸ’¡ å…³é”®å‘ç°:\n")
	if maxThroughput > 50000 {
		fmt.Printf("   ğŸ‰ æ€§èƒ½ä¼˜ç§€: è¶…è¿‡5ä¸‡records/sec\n")
	} else if maxThroughput > 20000 {
		fmt.Printf("   ğŸ‘ æ€§èƒ½è‰¯å¥½: è¶…è¿‡2ä¸‡records/sec\n")
	} else {
		fmt.Printf("   âš ï¸  æ€§èƒ½ä¸€èˆ¬: éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–\n")
	}

	// æ¨èé…ç½®
	var stableConcurrency int
	for _, concurrency := range concurrencyLevels {
		if result, exists := results[concurrency]; exists {
			if result["error_rate"].(float64) < 5 {
				stableConcurrency = concurrency
			}
		}
	}

	fmt.Printf("\nğŸ›¡ï¸  ç”Ÿäº§ç¯å¢ƒå»ºè®®:\n")
	if stableConcurrency > 0 {
		fmt.Printf("   ç¨³å®šè¿è¡Œ: %d å¹¶å‘ (é”™è¯¯ç‡ < 5%%)\n", stableConcurrency)
	}
	fmt.Printf("   å³°å€¼æ€§èƒ½: %d å¹¶å‘\n", optimalConcurrency)
	fmt.Printf("   å»ºè®®æ‰¹æ¬¡: 10,000-50,000 records\n")
	fmt.Printf("   å»ºè®®è¶…æ—¶: 60-120ç§’\n")

	fmt.Printf("========================================================\n")
}

// generateTestData ç”Ÿæˆæµ‹è¯•æ•°æ® - ä¼˜åŒ–ç‰ˆæœ¬
func generateTestData(workerID, batchSize int) string {
	// é¢„åˆ†é…å­—ç¬¦ä¸²ç©ºé—´ï¼Œæé«˜æ€§èƒ½
	estimatedSize := batchSize * 120 // æ¯æ¡è®°å½•çº¦120å­—èŠ‚
	data := make([]byte, 0, estimatedSize)

	for i := 0; i < batchSize; i++ {
		orderID := fmt.Sprintf("PERF_W%d_R%d_%d", workerID, i, time.Now().UnixNano())
		record := fmt.Sprintf("%s,Customer_%d,Product_%d,Electronics,Brand_%d,1,99.99,99.99,Shipped,2024-01-01,Region_%d\n",
			orderID, i%1000, i%100, i%50, i%10)
		data = append(data, record...)
	}
	return string(data)
}
